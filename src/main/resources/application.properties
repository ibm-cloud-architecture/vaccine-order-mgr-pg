# Configuration file
quarkus.log.console.format=%d{HH:mm:ss} %-5p [%c{2.}] (%t) %s%e%n
quarkus.log.console.level=INFO

# Build time properties
quarkus.swagger-ui.always-include=true
# When deploying as openshift app using s2i for example
quarkus.openshift.expose=true
quarkus.openshift.labels.app=vaccineorderms
quarkus.container-image.registry=image-registry.openshift-image-registry.svc:5000
quarkus.container-image.name=vaccineorderms
quarkus.container-image.group=ibmcase
quarkus.openshift.env.configmaps=vaccine-order-ms-cm
quarkus.openshift.env.configmaps=kafka-topics-cm
quarkus.openshift.env.secrets=vaccine-order-secrets
#################################
# Source to Image to openshift 
# 
# Define properties for yaml files generation
# Cluster certificate
quarkus.openshift.env.mapping.KAFKA_SSL_TRUSTSTORE_PASSWORD.from-secret=${KAFKA_CA_CERT_NAME:kafka-cluster-ca-cert}
quarkus.openshift.env.mapping.KAFKA_SSL_TRUSTSTORE_PASSWORD.with-key=ca.password
quarkus.openshift.mounts.kafka-cert.path=/deployments/certs/server
quarkus.openshift.secret-volumes.kafka-cert.secret-name=${KAFKA_CA_CERT_NAME:kafka-cluster-ca-cert}

# TLS user
quarkus.openshift.env.mapping.KAFKA_SSL_KEYSTORE_PASSWORD.from-secret=${KAFKA_USER:tls-user}
quarkus.openshift.env.mapping.KAFKA_SSL_KEYSTORE_PASSWORD.with-key=user.password
quarkus.openshift.mounts.user-cert.path=/deployments/certs/user
quarkus.openshift.secret-volumes.user-cert.secret-name=${KAFKA_USER:tls-user}
#################################
# Hibernate to postgres
quarkus.openshift.env.mapping.QUARKUS_DATASOURCE_JDBC_URL.from-secret=postgresql-creds
quarkus.openshift.env.mapping.QUARKUS_DATASOURCE_JDBC_URL.with-key=url
quarkus.openshift.env.mapping.QUARKUS_DATASOURCE_USERNAME.from-secret=postgresql-creds
quarkus.openshift.env.mapping.QUARKUS_DATASOURCE_USERNAME.with-key=username
quarkus.openshift.env.mapping.QUARKUS_DATASOURCE_PASSWORD.from-secret=postgresql-creds
quarkus.openshift.env.mapping.QUARKUS_DATASOURCE_PASSWORD.with-key=password
quarkus.datasource.db-kind=postgresql
quarkus.datasource.username=postgres
quarkus.datasource.password=pgpwd
#quarkus.datasource.=ordersdb
quarkus.hibernate-orm.database.generation=drop-and-create
quarkus.hibernate-orm.log.sql=true
quarkus.hibernate-orm.sql-load-script=import.sql
quarkus.hibernate-orm.dialect=org.hibernate.dialect.PostgreSQLDialect
quarkus.datasource.jdbc=true
quarkus.datasource.health.enabled=false
%dev.databasehost=localhost
%staging.databasehost=localhost
quarkus.datasource.jdbc.url=jdbc:postgresql://${databasehost}:5432/orderdb
quarkus.datasource.jdbc.max-size=8


app.transportationURL=http://localhost:8082/transportation

#################################
# Outbox setting for Quarkus Debezium plugin
quarkus.debezium-outbox.id.name=id
%prod.quarkus.debezium-outbox.id.column-definition="DECIMAL NOT NULL"
quarkus.index-dependency.outbox.group-id=io.debezium
quarkus.index-dependency.outbox.artifact-id=debezium-quarkus-outbox
quarkus.debezium-outbox.table-name=orderevents
# change to true in prod
quarkus.debezium-outbox.remove-after-insert=true

#################################
# Kafka config
quarkus.kafka.health.enabled=false

%prod.kafka.ssl.trustore.location=/deployments/certs/server/ca.p12
%prod.kafka.ssl.trustore.type=PKCS12
%prod.kafka.ssl.keystore.location=/deployments/certs/user/user.p12
%prod.kafka.ssl.keystore.type=PKCS12

%staging.kafka.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username\=\"${KAFKA_USER}\" password\=\"${KAFKA_PASSWORD}\";
%staging.kafka.sasl.mechanism=SCRAM-SHA-512

mp.messaging.incoming.shipments.connector=smallrye-kafka
mp.messaging.incoming.shipments.topic=${SHIPMENT_PLAN_TOPIC:vaccine.shipment.plans}
mp.messaging.incoming.shipments.group.id=order_mgr
mp.messaging.incoming.shipments.group.instance.id=order_mgr_1
mp.messaging.incoming.shipments.auto.offset.reset=earliest
mp.messaging.incoming.shipments.enable.auto.commit=true
mp.messaging.incoming.shipments.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
#mp.messaging.incoming.shipments.value.deserializer=ibm.gse.eda.vaccines.infrastructure.ShipmentDeserializer
# io.vertx.kafka.client.serialization.JsonObjectDeserializer

mp.messaging.incoming.shipments.value.deserializer=io.apicurio.registry.utils.serde.AvroKafkaDeserializer
mp.messaging.incoming.shipments.apicurio.registry.url=${SCHEMA_REGISTRY_URL}
%prod.mp.messaging.incoming.shipments.apicurio.registry.request.ssl.truststore.location=${KAFKA_SSL_TRUSTSTORE_LOCATION}
%prod.mp.messaging.incoming.shipments.apicurio.registry.request.ssl.truststore.password=${KAFKA_SSL_TRUSTSTORE_PASSWORD}
%prod.mp.messaging.incoming.shipments.apicurio.registry.request.ssl.truststore.type=${KAFKA_SSL_TRUSTSTORE_TYPE:PKCS12}
mp.messaging.incoming.shipments.specific.avro.reader=true
mp.messaging.incoming.shipments.apicurio.registry.avro-datum-provider=io.apicurio.registry.utils.serde.avro.ReflectAvroDatumProvider
mp.messaging.incoming.shipments.apicurio.registry.as-confluent=true